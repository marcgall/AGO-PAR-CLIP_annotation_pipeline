#
# Pipeline for annotation of raw reads from AGO-PARCLIP sequence data.
#
# Specific settings can be changed in the VARIABLES below.
# Note, however, that the downloading of human mature miRs from mirbase is
# currently hardcoded.
#
# At any step, the pipeline is superceded by the presence of correctly named
# files, by which downloading or processing new files can be avoided. Similarly,
# the 'temp()' tag can be removed in the rules if automatic cleanup is not
# desired.
#
import os
import csv

### HELPER FUNCTIONS
def get_samples(path = "SRR.csv"):
    """
    Read first columns in csv file as the SRR identifers and returns as list.
    First line is assumed to contain column names and thus skipped.
    """
    SRRs = []
    with open(path, "r") as fp:
        csv_reader = csv.reader(fp, delimiter = ",")
        line_count = 0
        for row in csv_reader:
            line_count += 1
            if line_count == 1:
                continue
            SRRs.append(row[0])
    return(SRRs)

### VARIABLES:
# Index name
REFERENCE_GENOME = "hg38" #hg19
# Index download
REFERENCE_GENOME_ADDRESS="ftp://hgdownload.soe.ucsc.edu/goldenPath/" + REFERENCE_GENOME + "/bigZips/"+ REFERENCE_GENOME + ".2bit"
# Read pre-processing
SAMPLES = get_samples()
ADAPTOR = "TGGAATTCTCGGGTGCCAAGG"
CUTADAPT_PARAMS = "-m 15"
# Read mapping
BOWTIE_PARAMS = "-v 2 -m 10 --best --strata"
# PARalyzer:
PARALYZER_METHOD = "HAFNER_APPROACH" #Options: EXTEND_BY_READ or ADDITIONAL_NUCLEOTIDES_BEYOND_SIGNAL=#integer#
PARALYZER_MEMORY = 8

rule final_output:
    input:
        expand("PARalyzer/annotated/{samples}.{type}.annotated.csv", samples = SAMPLES, type=["clusters", "groups", "miRTargets"])

#Creation of dummy variable to split task.
rule initialize_datasets:
    output:
        temp(expand("dummy/{sample}.dummy", sample = SAMPLES))
    shell:
        "touch {output}"

rule download_fastq:
    input:
        "dummy/{sample}.dummy"
    output:
        "raw_data/{sample}.fastq"
    shell:
        """
        cd raw_data/
        wget -c ftp://ftp.sra.ebi.ac.uk/vol1/fastq/`echo {wildcards.sample} | cut -c 1-6`/00`echo {wildcards.sample} | rev | cut -c 1`/{wildcards.sample}/{wildcards.sample}.fastq.gz
        gunzip {wildcards.sample}.fastq.gz
        cd ..
        """

rule cutadapt:
    input:
        "raw_data/{sample}.fastq"
    output:
        temp("data/{sample}.fastq")
    threads:
        8
    conda:
        "envs/bowtie.yaml"
    shell:
        "cutadapt -a {ADAPTOR} -j {threads} {CUTADAPT_PARAMS} "
        "-o {output} {input}"

rule bowtie:
    input:
        fastq="data/{sample}.fastq",
        index=expand("bowtie_index/index/{ref}.rev.1.ebwt", ref=REFERENCE_GENOME)
    output:
        temp("mapped_reads/{sample}.sam")
    threads:
        8
    conda:
        "envs/bowtie.yaml"
    shell:
        "bowtie {BOWTIE_PARAMS} -p {threads} "
        "bowtie_index/index/{REFERENCE_GENOME} -q {input.fastq} -S {output}"

rule samtools_sort:
    input:
        "mapped_reads/{sample}.sam"
    output:
        temp("mapped_reads/{sample}.sort.sam")
    threads:
        4
    conda:
        "envs/bowtie.yaml"
    shell:
        "samtools sort -O sam -@ {threads} {input} > {output}"

rule samtools_view:
    input:
        "mapped_reads/{sample}.sort.sam"
    output:
        temp("mapped_reads_sam/{sample}.sam")
    conda:
        "envs/bowtie.yaml"
    shell:
        "samtools view -hS -F 4 {input} > {output}"

rule download_reference:
    output:
        expand("bowtie_index/reference_genome/{ref}.2bit", ref = REFERENCE_GENOME)
    shell:
        """
        cd bowtie_index/reference_genome/
        wget -c {REFERENCE_GENOME_ADDRESS}
        cd ../..
        """

rule ref_2bit_to_fasta:
    input:
        "bowtie_index/reference_genome/{ref}.2bit"
    output:
        "bowtie_index/reference_genome/{ref}.fa"
    conda:
        "envs/bowtie.yaml"
    shell:
        "twoBitToFa {input} {output}"

rule ref_fasta_to_2bit:
    input:
        "bowtie_index/reference_genome/{ref}.fa"
    output:
        "bowtie_index/reference_genome/{ref}.2bit"
    conda:
        "envs/bowtie.yaml"
    shell:
        "faToTwoBit {input} {output}"

#NOTE: The output file is only 1 of 6 generated by bowtie. The rest are detected
#      automatically by exuction in the index/ directory.
rule calculate_index:
    input:
        "bowtie_index/reference_genome/{ref}.fa"
    output:
        "bowtie_index/index/{ref}.rev.1.ebwt"
    threads:
        8
    conda:
        "envs/bowtie.yaml"
    shell:
        """
        cd bowtie_index/index/
        bowtie-build --threads {threads} --quiet ../reference_genome/{wildcards.ref}.fa {wildcards.ref}
        touch {wildcards.ref}.dummy
        cd ../..
        """

#download mature mir sequence from miRbase. Only human sequences are selected.
#NOTE: second grep step is only relevant for older versions of grep (like on mac), to remove separators.
rule download_mir_ref:
    output:
        "mir_ref/mature.csv"
    conda:
        "envs/R.yaml"
    shell:
        """
        wget -c ftp://mirbase.org/pub/mirbase/CURRENT/mature.fa.gz
        gunzip -f mature.fa.gz
        grep -A1 "Homo sapiens" mature.fa | grep -v "^--$" > mir_ref/mature.fa
        rm mature.fa
        Rscript --vanilla scripts/fasta2csv.R mir_ref/mature.fa {output} 2> /dev/null
        """
        #NOTE: Modified the script to accept output as second argument, so it can be made generic.
        #NOTE: This rule is kind of messy as it is. Should clean up the input/output.

rule download_PARalyzer:
    output:
        "PARalyzer/PARalyzer_v1_5/Default_PARalyzer_Parameters.ini",
        "PARalyzer/PARalyzer_v1_5/PARalyzer"
    shell:
        """
        cd PARalyzer/
        wget -c https://ohlerlab.mdc-berlin.de/files/duke/PARalyzer/PARalyzer_v1_5.tar.gz
        tar xvzf PARalyzer_v1_5.tar.gz
        rm PARalyzer_v1_5.tar.gz
        """

#Make custom ini file for PARalyzer
rule PARalyzer_ini:
    input:
        twoBit=expand("bowtie_index/reference_genome/{ref}.2bit", ref=REFERENCE_GENOME),
        mapped="mapped_reads_sam/{sample}.sam",
        mir_ref="mir_ref/mature.csv",
        PARalyzer="PARalyzer/PARalyzer_v1_5/Default_PARalyzer_Parameters.ini"
    output:
        "PARalyzer/ini/{sample}.PARalyzer.ini"
    params:
        max_seed_length=8
    shell:
        """
        cp {input.PARalyzer} {output}
        sed -i s/EXTEND_BY_READ/{PARALYZER_METHOD}/ {output}
        sed -i s/GENOME_2BIT_FILE.*// {output}
        echo "GENOME_2BIT_FILE="$PWD"/bowtie_index/reference_genome/{REFERENCE_GENOME}.2bit" >> {output}
        echo "SAM_FILE="$PWD"/{input.mapped}" >> {output}
        echo "OUTPUT_CLUSTERS_FILE="$PWD"/PARalyzer/output/{wildcards.sample}.clusters.csv" >> {output}
        echo "OUTPUT_GROUPS_FILE="$PWD"/PARalyzer/output/{wildcards.sample}.groups.csv" >> {output}
        echo "OUTPUT_DISTRIBUTIONS_FILE="$PWD"/PARalyzer/output/{wildcards.sample}.dist.csv" >> {output}
        echo "FIND_MIRNA_SEEDMATCHES="$PWD"/{input.mir_ref}" >> {output}
        echo "MAXIMUM_SEED_MATCH_LENGTH={params.max_seed_length}" >> {output}
        echo "OUTPUT_MIRNA_TARGETS_FILE="$PWD"/PARalyzer/output/{wildcards.sample}.miRTargets.csv" >> {output}
        """

rule run_PARalyzer:
    input:
        ini="PARalyzer/ini/{sample}.PARalyzer.ini",
        PARalyzer="PARalyzer/PARalyzer_v1_5/PARalyzer",
        mapped="mapped_reads_sam/{sample}.sam"
    output:
        "PARalyzer/output/{sample}.clusters.csv",
        "PARalyzer/output/{sample}.groups.csv",
        "PARalyzer/output/{sample}.dist.csv",
        "PARalyzer/output/{sample}.miRTargets.csv"
    params:
        path="PARalyzer/PARalyzer_v1_5/",
        mem=PARALYZER_MEMORY
    conda:
        "envs/PARalyzer.yaml"
    shell:
        """
        SNAKEDIR=$PWD
        cd {params.path}
        ./PARalyzer {params.mem}G $SNAKEDIR/{input.ini}
        cd $SNAKEDIR
        """

#Add genetic annotation to the clusters and mir targets:
#Std.err is suppressed to stop R printing package info to output.
rule annotate:
    input:
        "PARalyzer/output/{sample_type}.csv"
    output:
        "PARalyzer/annotated/{sample_type}.annotated.csv"
    params:
        sc="scripts/annotate_ranges.R",
        hg=REFERENCE_GENOME
    conda:
        "envs/R.yaml"
    shell:
        "Rscript --vanilla {params.sc} {input} {output} {params.hg} 2> /dev/null"
